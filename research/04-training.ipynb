{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\gkart\\\\Desktop\\\\1-ProjectENDtoEND\\\\chicken_disease_classification'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\gkart\\\\Desktop\\\\1-ProjectENDtoEND\\\\chicken_disease_classification'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen =True)\n",
    "class TrainingConfig:\n",
    "    root_dir:Path\n",
    "    trained_model_path:Path\n",
    "    updated_base_model_path:Path\n",
    "    training_data : Path\n",
    "    params_epochs: int\n",
    "    params_batch_size:int\n",
    "    params_is_augmentation :bool\n",
    "    params_image_size:list\n",
    "    # writing extra variables as we need the parameters and training data and base model to train the model and make predictions\n",
    "\n",
    "# Note : Since i have not created any seprate pipeline for callbacks i am going to integrate that code of call backs here only \n",
    "# because callbacks are ideally used while model training only.\n",
    "@dataclass(frozen =True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir:Path\n",
    "    tensorboard_root_log_dir:Path\n",
    "    checkpoint_model_filepath:Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - creating entity\n",
    "from src.chickenDiseaseClassifier.constants import *\n",
    "from src.chickenDiseaseClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "\n",
    "    def __init__(self,config_filepath = CONFIG_FILE_PATH, params_filepath = PARAM_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.param = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    # As said earlier also embedding the code from callbacks part as well.\n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        # This is a function from the os.path module that returns the directory name component of a given file path. \n",
    "        # It takes the file path as an argument and extracts the directory part, excluding the file name\n",
    "        create_directories([Path(model_ckpt_dir),Path(config.tensorboard_root_log_dir)])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(root_dir = config.root_dir, \n",
    "                                                         tensorboard_root_log_dir = config.tensorboard_root_log_dir,\n",
    "                                                         checkpoint_model_filepath = config.checkpoint_model_filepath\n",
    "                                                        )\n",
    "        return prepare_callback_config\n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        param = self.param\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir , \"Chicken-fecal-images\")\n",
    "        create_directories([training.root_dir])\n",
    "\n",
    "        training_config = TrainingConfig(   root_dir = training.root_dir,\n",
    "                                            trained_model_path= training.trained_model_path,\n",
    "                                            updated_base_model_path = self.config.prepare_base_model.updated_base_model_path,\n",
    "                                            training_data = Path(training_data),\n",
    "                                            params_epochs= param.EPOCHS,\n",
    "                                            params_batch_size= param.BATCH_SIZE,\n",
    "                                            params_is_augmentation  =param.AUGMENTATION,\n",
    "                                            params_image_size= param.IMAGE_SIZE\n",
    "                                            )\n",
    "        return training_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating components\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class PrepareCallback:\n",
    "    def __init__(self,config : PrepareCallbacksConfig):\n",
    "        self.config  =config\n",
    "    \n",
    "    @property\n",
    "    #  This is a Python decorator that marks the method as a property.\n",
    "    #  It allows the method to be accessed like an attribute without the need for explicit function call parentheses.\n",
    "    def create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(self.config.tensorboard_root_log_dir, f\"tensorboard_logs_at_{timestamp}\")\n",
    "        \n",
    "\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir  = tb_running_log_dir)\n",
    "        # The code snippet tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir) creates a TensorBoard callback \n",
    "        # instance in TensorFlow Keras. \n",
    "        # This callback is used to log training and evaluation metrics during the model training process at the specified position. \n",
    "\n",
    "    @property\n",
    "    def create_checkpoint_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(self.config.checkpoint_model_filepath,save_best_only=True)\n",
    "    # It is used to save the model's weights during the training process\n",
    "\n",
    "    def get_ckpt_tb_callbacks(self):\n",
    "        return [self.create_tb_callbacks , self.create_checkpoint_callbacks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config : TrainingConfig):\n",
    "        self.config  =config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(self.config.updated_base_model_path)\n",
    "    \n",
    "    def train_valid_generator(self):\n",
    "# This method will be used to do data_augumentation on the fly.\n",
    "\n",
    "        datagenerator_kwargs ={\"validation_split\" :0.2,\"rescale\" : 1./255}\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator( **datagenerator_kwargs)\n",
    "        # This is the valid_datagenerator i am creating for validation data\n",
    "        #  This ImageDataGenerator class in TensorFlow (tf.keras) is a powerful tool for generating augmented batches of \n",
    "        # image data during model training. It is primarily used in deep learning tasks, particularly in computer vision\n",
    "        #  applications, to apply data augmentation techniques to image data.\n",
    "        # Note : Validation_split = 0.2 will not create any separate folders in my training_data directory.The generator doesn't create separate \"validation\" and \n",
    "        # \"training\" folders. Instead, it generates batches of data on-the-fly, following the split ratio you've specified.\n",
    "        # In Python, the double asterisk ** is used to pass a dictionary as a set of keyword arguments to a function or method. \n",
    "\n",
    "\n",
    "        dataflow_kwargs = {\"target_size\" : self.config.params_image_size[:-1], \"batch_size\" : self.config.params_batch_size,\"interpolation\": \"bilinear\"}\n",
    "\n",
    "        self.validgenerator = valid_datagenerator.flow_from_directory(directory= self.config.training_data, subset=\"validation\", shuffle= \"False\",**dataflow_kwargs)\n",
    "        \n",
    "        # The flow_from_directory() method takes a path of a directory and generates batches of augmented data.\n",
    "        # subset: This parameter is set to \"validation,\" indicating that you want to generate data for validation purposes.\n",
    "        #  This assumes that your dataset is structured in a way that you have a separate subdirectory for training data and\n",
    "        #  another one for validation data.\n",
    "\n",
    "        train_datagenerator = valid_datagenerator\n",
    "        # this is the train_datagenerator i am creating for training data. as of now for simplicity i am keeping both the \n",
    "        # training and validation datagenerator as same or equal\n",
    "\n",
    "        self.traingenerator = train_datagenerator.flow_from_directory(directory = self.config.training_data, subset = \"training\",shuffle = \"False\",**dataflow_kwargs)\n",
    "        # This subset= training means data generator will only load the images and labels that are designated as training data.\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path: Path,model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self,callbacks :list):\n",
    "        self.model.fit(self.traingenerator,epochs = self.config.params_epochs,batch_size = self.config.params_batch_size,\n",
    "                       validation_data=self.validgenerator,callbacks = callbacks)\n",
    "    # I am using the augumented data returned by traingenerator created in above function\n",
    "    # callbacks: This is a list of callbacks that will be used to monitor the training process and to intervene if necessary.\n",
    "\n",
    "    # A callback is a set of functions to be applied at given stages of the training procedure.\n",
    "    # pass a list of callbacks (as the keyword argument callbacks ) to the . fit() method of the Sequential or Model classes.\n",
    "\n",
    "        self.save_model(self.config.trained_model_path,self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-08 15:51:57,931: INFO: common: yaml file : config\\config.yaml loaded sucesfully]\n",
      "[2023-08-08 15:51:57,946: INFO: common: yaml file : params.yaml loaded sucesfully]\n",
      "[2023-08-08 15:51:57,951: INFO: common: Create directory at : artifacts]\n",
      "[2023-08-08 15:51:57,957: INFO: common: Create directory at : artifacts/training]\n",
      "[2023-08-08 15:51:57,962: INFO: common: Create directory at : artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2023-08-08 15:51:57,968: INFO: common: Create directory at : artifacts\\prepare_callbacks\\tensorboard_log_dir]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Training' object has no attribute 'training_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     training\u001b[39m.\u001b[39mtrain(callbacks)\n\u001b[0;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     training \u001b[39m=\u001b[39m Training(training_config)\n\u001b[0;32m      9\u001b[0m     training\u001b[39m.\u001b[39mget_base_model()\n\u001b[1;32m---> 10\u001b[0m     training\u001b[39m.\u001b[39;49mtrain_valid_generator()\n\u001b[0;32m     11\u001b[0m     training\u001b[39m.\u001b[39mtrain(callbacks)\n\u001b[0;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[23], line 36\u001b[0m, in \u001b[0;36mTraining.train_valid_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m train_datagenerator \u001b[39m=\u001b[39m valid_datagenerator\n\u001b[0;32m     33\u001b[0m \u001b[39m# this is the train_datagenerator i am creating for training data. as of now for simplicity i am keeping both the \u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# training and validation datagenerator as same or equal\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraingenerator \u001b[39m=\u001b[39m train_datagenerator\u001b[39m.\u001b[39mflow_from_directory(directory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_data, subset \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m,shuffle \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFalse\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataflow_kwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Training' object has no attribute 'training_data'"
     ]
    }
   ],
   "source": [
    "# creating pipeline\n",
    "try:\n",
    "    configuration_manager = ConfigurationManager()\n",
    "    training_config = configuration_manager.get_training_config()\n",
    "    callback_config = configuration_manager.get_prepare_callback_config()\n",
    "    callback_obj1 = PrepareCallback(callback_config)\n",
    "    callbacks = callback_obj1.get_ckpt_tb_callbacks()\n",
    "    training = Training(training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(callbacks)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
